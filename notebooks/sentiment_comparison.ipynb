{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Showdown: Custom LSTM vs. XLM-RoBERTa\n",
    "\n",
    "\n",
    "In questo notebook confronteremo due approcci alla Sentiment Analysis usando il dataset `mental.csv` (colonne `statement` e `status`).\n",
    "\n",
    "\n",
    "- Il dataset viene mescolato casualmente e suddiviso in: 81% train, 9% val (entrambi ricavati dal 90% del totale) e 10% test (usato **solo** nel confronto finale tra i modelli).\n",
    "\n",
    "\n",
    "- Useremo lo stesso split per l'addestramento del modello LSTM e per il fine-tuning di XLM-RoBERTa (con LoRA).\n",
    "\n",
    "\n",
    "- Includiamo una WordCloud sull'insieme di training per un'EDA veloce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: torch in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: accelerate in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: peft in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from wordcloud) (12.0.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installazione dipendenze (se necessario)\n",
    "!pip install transformers datasets wordcloud gensim seaborn torch scikit-learn pandas matplotlib accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import gensim.downloader as api\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset as HFDataset\n",
    "from peft import PeftModel, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Configurazione Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mental (bilanciato) size: 30305\n",
      "Classi: {'depression': 0, 'light': 1, 'normal': 2, 'serious': 3}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Caricamento dati: dataset mental bilanciato da 1_EDA_and_Baseline.ipynb\n",
    "mental_path = '../data/processed/mental_balanced.csv'\n",
    "df_mental = pd.read_csv(mental_path)\n",
    "\n",
    "# Usa la colonna 'target' (già mappata e bilanciata) come sentiment, 'statement' come testo\n",
    "df_mental = df_mental.rename(columns={'statement': 'review_text', 'target': 'sentiment'})\n",
    "\n",
    "df_mental = df_mental[['review_text', 'sentiment']].dropna()\n",
    "df_mental['review_text'] = df_mental['review_text'].astype(str)\n",
    "df_mental['sentiment'] = df_mental['sentiment'].astype(str).str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Costruisci mapping etichette dinamico (ordinamento alfabetico)\n",
    "labels_order = sorted(df_mental['sentiment'].unique())\n",
    "sentiment_map = {label: idx for idx, label in enumerate(labels_order)}\n",
    "reverse_sentiment_map = {v: k for k, v in sentiment_map.items()}\n",
    "df_mental['label'] = df_mental['sentiment'].map(sentiment_map)\n",
    "\n",
    "\n",
    "# Shuffle esplicito per tutto il dataset\n",
    "df_mental = df_mental.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Dataset mental (bilanciato) size: {len(df_mental)}\")\n",
    "print(f\"Classi: {sentiment_map}\")\n",
    "\n",
    "\n",
    "# Distribuzione classi sul dataset completo\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=df_mental, order=labels_order)\n",
    "plt.title('Distribuzione classi - mental_balanced.csv')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suddivisione: 81% train, 9% val (da 90% tot), 10% test (solo confronto finale)\n",
    "test_size = 0.10\n",
    "stratify_all = df_mental['label'] if df_mental['label'].nunique() > 1 else None\n",
    "\n",
    "train_val_df, test_df = train_test_split(\n",
    "    \n",
    "    df_mental[['review_text', 'sentiment', 'label']],\n",
    "    test_size=test_size,\n",
    "    random_state=42,\n",
    "    stratify=stratify_all\n",
    ")\n",
    "\n",
    "\n",
    "# Per ottenere 9% val sul totale: 0.10 / 0.90 ≈ 0.1111 della parte train_val\n",
    "val_fraction = test_size / (1 - test_size)\n",
    "stratify_train_val = train_val_df['label'] if train_val_df['label'].nunique() > 1 else None\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "\n",
    "    train_val_df,\n",
    "    test_size=val_fraction,\n",
    "    random_state=42,\n",
    "    stratify=stratify_train_val\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Train size: {len(train_df)} | Val size: {len(val_df)} | Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione WordCloud sul dataset di training (mental)\n",
    "text_combined = \" \".join(review for review in train_df.review_text)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=200).generate(text_combined)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud delle recensioni (train - mental.csv)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modello 1: Custom LSTM (con GloVe Twitter)\n",
    "\n",
    "Replichiamo l'architettura del notebook precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Preprocessing specifico per LSTM ---\n",
    "def clean_text_lstm(text):\n",
    "\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # conserva emoji/emoticon rimuovendo solo url e caratteri di controllo\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[\\r\\n\\t]+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s\\U0001F300-\\U0001FAFF]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Applica il preprocessing e tokenizza le partizioni (train/val/test dal mental split)\n",
    "def add_tokens(df_in):\n",
    "    df_out = df_in.copy()\n",
    "    df_out['clean_text'] = df_out['review_text'].apply(clean_text_lstm)\n",
    "    df_out['tokens'] = df_out['clean_text'].apply(lambda x: x.split())\n",
    "    return df_out\n",
    "\n",
    "\n",
    "train_df_lstm = add_tokens(train_df)\n",
    "val_df_lstm = add_tokens(val_df)\n",
    "test_df_lstm = add_tokens(test_df)\n",
    "\n",
    "\n",
    "# Vocabolario costruito solo sul training set\n",
    "all_words = [word for tokens in train_df_lstm['tokens'] for word in tokens]\n",
    "word_counts = Counter(all_words)\n",
    "min_freq = 2\n",
    "vocab_list = sorted([k for k, v in word_counts.items() if v >= min_freq])\n",
    "vocab = {word: i + 1 for i, word in enumerate(vocab_list)}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "\n",
    "# Conversione Testo -> Indici\n",
    "def text_to_indices(tokens, vocab, max_len=50):\n",
    "\n",
    "    indices = [vocab[token] for token in tokens if token in vocab]\n",
    "\n",
    "    if len(indices) < max_len:\n",
    "        indices += [0] * (max_len - len(indices))\n",
    "\n",
    "    else:\n",
    "        indices = indices[:max_len]\n",
    "\n",
    "    return indices\n",
    "\n",
    "max_seq_len = 50\n",
    "\n",
    "X_train_lstm = np.array([text_to_indices(tokens, vocab, max_seq_len) for tokens in train_df_lstm['tokens']])\n",
    "y_train_lstm = train_df_lstm['label'].values\n",
    "X_val_lstm = np.array([text_to_indices(tokens, vocab, max_seq_len) for tokens in val_df_lstm['tokens']])\n",
    "y_val_lstm = val_df_lstm['label'].values\n",
    "X_test_lstm = np.array([text_to_indices(tokens, vocab, max_seq_len) for tokens in test_df_lstm['tokens']])\n",
    "y_test_lstm = test_df_lstm['label'].values\n",
    "\n",
    "\n",
    "# Dataset PyTorch\n",
    "class ReviewDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_loader_lstm = DataLoader(ReviewDataset(X_train_lstm, y_train_lstm), batch_size=32, shuffle=True)\n",
    "val_loader_lstm = DataLoader(ReviewDataset(X_val_lstm, y_val_lstm), batch_size=32, shuffle=False)\n",
    "test_loader_lstm = DataLoader(ReviewDataset(X_test_lstm, y_test_lstm), batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# --- 2.2 Caricamento Embeddings GloVe ---\n",
    "print(\"Caricamento GloVe Twitter... (potrebbe richiedere un po')\")\n",
    "\n",
    "try:\n",
    "    glove_model = api.load(\"glove-twitter-100\")\n",
    "    embedding_dim = 100\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, idx in vocab.items():\n",
    "\n",
    "        if word in glove_model:\n",
    "            embedding_matrix[idx] = glove_model[word]\n",
    "\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore caricamento GloVe: {e}. Uso embedding random.\")\n",
    "    embedding_dim = 100\n",
    "    embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embedding_dim))\n",
    "\n",
    "\n",
    "# --- 2.3 Definizione Modello ---\n",
    "class SentimentLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        return self.fc(self.dropout(hidden))\n",
    "\n",
    "\n",
    "# --- 2.4 Training Loop ---\n",
    "model_lstm = SentimentLSTM(vocab_size, embedding_dim, 64, len(sentiment_map), embedding_matrix).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training LSTM...\")\n",
    "\n",
    "lstm_val_history = []\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_lstm.train()\n",
    "\n",
    "    for X_b, y_b in train_loader_lstm:\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model_lstm(X_b)\n",
    "        loss = criterion(out, y_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model_lstm.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in val_loader_lstm:\n",
    "            X_b = X_b.to(device)\n",
    "            out = model_lstm(X_b)\n",
    "            _, preds = torch.max(out, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_targets.extend(y_b.numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_targets, val_preds)\n",
    "    lstm_val_history.append(val_acc)\n",
    "    print(f\"LSTM Epoch {epoch + 1}: Val Accuracy {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Test finale sul set di test (mental)\n",
    "model_lstm.eval()\n",
    "test_preds, test_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_b, y_b in test_loader_lstm:\n",
    "        X_b = X_b.to(device)\n",
    "        out = model_lstm(X_b)\n",
    "        _, preds = torch.max(out, 1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_targets.extend(y_b.numpy())\n",
    "\n",
    "lstm_test_acc = accuracy_score(test_targets, test_preds)\n",
    "lstm_test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "lstm_cm = confusion_matrix(test_targets, test_preds)\n",
    "\n",
    "print(f\"LSTM Test Accuracy (mental test): {lstm_test_acc:.4f} | F1-weighted: {lstm_test_f1:.4f}\")\n",
    "\n",
    "# Salvataggio checkpoint LSTM in ../models (overwrite)\n",
    "lstm_ckpt_dir = os.path.abspath(os.path.join('..', 'models'))\n",
    "os.makedirs(lstm_ckpt_dir, exist_ok=True)\n",
    "\n",
    "lstm_ckpt_path = os.path.join(lstm_ckpt_dir, 'lstm_sentiment.ckpt')\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_lstm.state_dict(),\n",
    "    'vocab': vocab,\n",
    "    'sentiment_map': sentiment_map,\n",
    "}, lstm_ckpt_path)\n",
    "\n",
    "print(f\"Checkpoint LSTM salvato in {lstm_ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modello 2: XLM-RoBERTa (Fine-Tuning)\n",
    "\n",
    "Usiamo la libreria `transformers` per fine-tunare `xlm-roberta-base`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Preparazione Dati per Transformers (mental split) ---\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "X_train_raw, y_train_raw = train_df['review_text'], train_df['label']\n",
    "X_val_raw, y_val_raw = val_df['review_text'], val_df['label']\n",
    "X_test_raw, y_test_raw = test_df['review_text'], test_df['label']\n",
    "\n",
    "\n",
    "def tokenize_function(texts):\n",
    "\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "# Creazione Dataset HuggingFace\n",
    "train_dataset = HFDataset.from_dict({\"text\": X_train_raw.tolist(), \"label\": y_train_raw.tolist()})\n",
    "val_dataset = HFDataset.from_dict({\"text\": X_val_raw.tolist(), \"label\": y_val_raw.tolist()})\n",
    "test_dataset = HFDataset.from_dict({\"text\": X_test_raw.tolist(), \"label\": y_test_raw.tolist()})\n",
    "\n",
    "train_tokenized = train_dataset.map(lambda batch: tokenize_function(batch['text']), batched=True)\n",
    "val_tokenized = val_dataset.map(lambda batch: tokenize_function(batch['text']), batched=True)\n",
    "test_tokenized = test_dataset.map(lambda batch: tokenize_function(batch['text']), batched=True)\n",
    "\n",
    "\n",
    "# --- 3.2 Setup Trainer con LoRA ---\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(sentiment_map),\n",
    "    id2label=reverse_sentiment_map,\n",
    "    label2id=sentiment_map,\n",
    "    cache_dir=os.path.abspath(os.path.join('..', 'models'))\n",
    ").to(device)\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    modules_to_save=[\"classifier\"] # <--- Addestra e salva la testa di classificazione!\n",
    ")\n",
    "\n",
    "model_xlm = get_peft_model(base_model, peft_config)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "xlm_ckpt_dir = os.path.abspath(os.path.join('..', 'models', 'sentiment_lora_checkpoints'))\n",
    "xlm_final_dir = os.path.abspath(os.path.join('..', 'models', 'sentiment_lora'))\n",
    "os.makedirs(xlm_ckpt_dir, exist_ok=True)\n",
    "os.makedirs(xlm_final_dir, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=xlm_ckpt_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    overwrite_output_dir=True,\n",
    "    use_cpu=not torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_xlm,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# --- 3.3 Training ---\n",
    "print(\"Training XLM-RoBERTa LoRA...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Salva l'adapter LoRA (sovrascrive se esiste)\n",
    "model_xlm.save_pretrained(xlm_final_dir)\n",
    "tokenizer.save_pretrained(xlm_final_dir)\n",
    "\n",
    "# Valutazione Finale sul test (mental)\n",
    "print(\"Valutazione su mental test...\")\n",
    "\n",
    "test_pred = trainer.predict(test_tokenized)\n",
    "test_logits = test_pred.predictions\n",
    "test_labels = test_pred.label_ids\n",
    "test_preds = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "xlm_test_acc = accuracy_score(test_labels, test_preds)\n",
    "xlm_test_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "xlm_cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "\n",
    "print(f\"XLM-RoBERTa (LoRA) Test Accuracy (mental test): {xlm_test_acc:.4f} | F1-weighted: {xlm_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Confronto Risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix sul test set (mental)\n",
    "\n",
    "\n",
    "Confrontiamo le confusion matrix complete per i due modelli sulle etichette reali del test di `mental.csv` (hold-out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Custom LSTM (GloVe)', 'XLM-RoBERTa']\n",
    "\n",
    "accuracies = [lstm_test_acc, xlm_test_acc]\n",
    "f1_scores = [lstm_test_f1, xlm_test_f1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.barplot(ax=axes[0], x=models, y=accuracies, palette='viridis')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].set_title('Accuracy Modelli (mental test)')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0].text(i, v + 0.02, f\"{v:.4f}\", ha='center', fontweight='bold')\n",
    "\n",
    "sns.barplot(ax=axes[1], x=models, y=f1_scores, palette='magma')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_title('F1-weighted Modelli (mental test)')\n",
    "axes[1].set_ylabel('F1-weighted')\n",
    "\n",
    "for i, v in enumerate(f1_scores):\n",
    "    axes[1].text(i, v + 0.02, f\"{v:.4f}\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_plot = labels_order\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(lstm_cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_for_plot, yticklabels=labels_for_plot, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - LSTM (mental test)')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "sns.heatmap(xlm_cm, annot=True, fmt='d', cmap='Greens', xticklabels=labels_for_plot, yticklabels=labels_for_plot, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - XLM-RoBERTa (mental test)')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confronto rapido: LSTM vs BERT pre-addestrato su 30 esempi (mental test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona un campione casuale di 30 righe dal test set (mental)\n",
    "n_eval = min(1000, len(test_df_lstm))\n",
    "eval_df = test_df_lstm.sample(n=n_eval, random_state=42).copy()\n",
    "y_true = eval_df['sentiment'].str.lower().tolist()\n",
    "\n",
    "\n",
    "# --- Predizioni LSTM sul sottoinsieme ---\n",
    "X_eval_lstm = np.array([text_to_indices(tokens, vocab, max_seq_len) for tokens in eval_df['tokens']])\n",
    "\n",
    "lstm_preds = []\n",
    "model_lstm.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(0, len(X_eval_lstm), 32):\n",
    "        batch = torch.tensor(X_eval_lstm[i:i+32], dtype=torch.long).to(device)\n",
    "        logits = model_lstm(batch)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "\n",
    "        lstm_preds.extend([reverse_sentiment_map[p.item()].lower() for p in preds.cpu()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Predizioni BERT già addestrato (LoRA se presente) ---\n",
    "lora_path = os.path.abspath(os.path.join('..', 'models', 'sentiment_lora'))\n",
    "base_name = 'xlm-roberta-base'\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(lora_path if os.path.exists(lora_path) else base_name)\n",
    "\n",
    "bert_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_name,\n",
    "    num_labels=len(sentiment_map),\n",
    "    id2label=reverse_sentiment_map,\n",
    "    label2id=sentiment_map,\n",
    "    cache_dir=os.path.abspath(os.path.join('..', 'models'))\n",
    ")\n",
    "\n",
    "if os.path.exists(os.path.join(lora_path, 'adapter_config.json')):\n",
    "    bert_model = PeftModel.from_pretrained(bert_base, lora_path)\n",
    "\n",
    "else:\n",
    "    bert_model = bert_base\n",
    "\n",
    "bert_model.to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "def predict_bert(texts, batch_size=8):\n",
    "    preds = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = bert_tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = bert_model(**inputs).logits\n",
    "\n",
    "        class_ids = torch.argmax(logits, dim=-1).cpu().tolist()\n",
    "        preds.extend([bert_model.config.id2label[c] for c in class_ids])\n",
    "\n",
    "    return [p.lower() for p in preds]\n",
    "\n",
    "bert_preds = predict_bert(eval_df['review_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriche di classificazione su 30 esempi casuali (mental test)\n",
    "labels_eval = labels_order\n",
    "\n",
    "def evaluate_run(name, preds):\n",
    "    acc = accuracy_score(y_true, preds)\n",
    "    print(f\"\\n{name} - Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_true, preds, labels=labels_eval, target_names=labels_eval, digits=3))\n",
    "\n",
    "    return acc, confusion_matrix(y_true, preds, labels=labels_eval)\n",
    "\n",
    "lstm_acc, cm_lstm = evaluate_run('LSTM', lstm_preds)\n",
    "bert_acc, cm_bert = evaluate_run('BERT (xlm-roberta + LoRA)', bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap delle confusion matrix + confronto accuracy\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_eval, yticklabels=labels_eval, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - LSTM (30 esempi mental)')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(cm_bert, annot=True, fmt='d', cmap='Greens', xticklabels=labels_eval, yticklabels=labels_eval, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - BERT (LoRA) (30 esempi mental)')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Bar chart accuracy\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "\n",
    "sns.barplot(x=['LSTM', 'BERT (LoRA)'], y=[lstm_acc, bert_acc], palette='magma')\n",
    "\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "\n",
    "for i, v in enumerate([lstm_acc, bert_acc]):\n",
    "\n",
    "\n",
    "    plt.text(i, v + 0.02, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
    "\n",
    "\n",
    "plt.title('Accuracy su 30 esempi mental test')\n",
    "\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
