{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Confronto Modelli su Dataset Bilanciato\n",
    "\n",
    "Questo notebook estende l'analisi precedente integrando:\n",
    "1.  **Data Engineering**: Aggregazione delle classi (`Serious`, `Light`) e ribilanciamento (Undersampling).\n",
    "2.  **Modelli**: \n",
    "    - **Naive Bayes (Baseline)**: TF-IDF + MultinomialNB\n",
    "    - **Custom LSTM**: Con GloVe embeddings\n",
    "    - **XLM-RoBERTa**: Fine-tuning con LoRA\n",
    "3.  **Confronto**: Metriche e grafici comparativi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: torch in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: accelerate in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: peft in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from wordcloud) (12.0.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gabs\\desktop\\faboulus-interpretr\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets wordcloud gensim seaborn torch scikit-learn pandas matplotlib accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import gensim.downloader as api\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset as HFDataset\n",
    "from peft import PeftModel, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Configurazione Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparazione Dati: Mapping e Bilanciamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7628\\568080365.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m             df_class = resample(df_class, replace=\u001b[38;5;28;01mFalse\u001b[39;00m, n_samples=max_samples, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     24\u001b[39m         balanced_dfs.append(df_class)\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.concat(balanced_dfs).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     26\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m df_balanced = balance_classes(df, \u001b[33m'label_str'\u001b[39m, max_samples=\u001b[32m8000\u001b[39m).shuffle(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Mappatura ID numerici\u001b[39;00m\n\u001b[32m     30\u001b[39m labels_order = sorted(df_balanced[\u001b[33m'label_str'\u001b[39m].unique())\n",
      "\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "# Caricamento Dataset\n",
    "df = pd.read_csv('../data/processed/mental.csv')\n",
    "df = df.rename(columns={'statement': 'review_text', 'status': 'sentiment'}).dropna()\n",
    "\n",
    "# 1. Mapping Classi (Aggregazione)\n",
    "def map_labels(label):\n",
    "    label = str(label).strip()\n",
    "    if label in ['Bipolar', 'Personality disorder', 'suicidal']:\n",
    "        return 'Serious'\n",
    "    elif label in ['Anxiety', 'Stress']:\n",
    "        return 'Light'\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "df['label_str'] = df['sentiment'].apply(map_labels)\n",
    "\n",
    "# 2. Bilanciamento (Undersampling a 7000)\n",
    "def balance_classes(df, target_col, max_samples=8000):\n",
    "    balanced_dfs = []\n",
    "    for label in df[target_col].unique():\n",
    "        df_class = df[df[target_col] == label]\n",
    "        if len(df_class) > max_samples:\n",
    "            df_class = resample(df_class, replace=False, n_samples=max_samples, random_state=42)\n",
    "        balanced_dfs.append(df_class)\n",
    "    return pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "df_balanced = balance_classes(df, 'label_str', max_samples=8000)\n",
    "\n",
    "# Mappatura ID numerici\n",
    "labels_order = sorted(df_balanced['label_str'].unique())\n",
    "label2id = {l: i for i, l in enumerate(labels_order)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "df_balanced['label'] = df_balanced['label_str'].map(label2id)\n",
    "\n",
    "# Visualizzazione Distribuzione\n",
    "print(f\"Classi finali: {labels_order}\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='label_str', data=df_balanced, palette='viridis', order=labels_order)\n",
    "plt.title('Distribuzione Classi (Bilanciata)')\n",
    "plt.show()\n",
    "\n",
    "# Split Train/Val/Test\n",
    "train_val, test_df = train_test_split(df_balanced, test_size=0.1, random_state=42, stratify=df_balanced['label'])\n",
    "train_df, val_df = train_test_split(train_val, test_size=0.1111, random_state=42, stratify=train_val['label'])\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes...\n",
      "Naive Bayes -> Accuracy: 0.6638 | F1: 0.6725\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Naive Bayes...\")\n",
    "model_nb = make_pipeline(\n",
    "    TfidfVectorizer(max_features=10000, stop_words='english'),\n",
    "    MultinomialNB()\n",
    " )\n",
    "model_nb.fit(train_df['review_text'], train_df['label'])\n",
    "\n",
    "# Valutazione\n",
    "nb_preds = model_nb.predict(test_df['review_text'])\n",
    "nb_acc = accuracy_score(test_df['label'], nb_preds)\n",
    "nb_f1 = f1_score(test_df['label'], nb_preds, average='weighted')\n",
    "print(f\"Naive Bayes -> Accuracy: {nb_acc:.4f} | F1: {nb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento GloVe...\n",
      "GloVe non disponibile, uso random.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m     68\u001b[39m opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m loss = crit(\u001b[43mmodel_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, y)\n\u001b[32m     70\u001b[39m loss.backward()\n\u001b[32m     71\u001b[39m opt.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mLSTMNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     55\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.emb(x)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     _, (h, _) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(\u001b[38;5;28mself\u001b[39m.drop(torch.cat((h[-\u001b[32m2\u001b[39m], h[-\u001b[32m1\u001b[39m]), dim=\u001b[32m1\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabs\\Desktop\\faboulus-interpretr\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing per LSTM\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "all_text = \" \".join(train_df['review_text'].apply(clean_text))\n",
    "vocab_counts = Counter(all_text.split())\n",
    "vocab = {w: i+1 for i, (w, c) in enumerate(vocab_counts.items()) if c >= 2}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "def encode(text, max_len=60):\n",
    "    tokens = clean_text(text).split()\n",
    "    vec = [vocab.get(t, 0) for t in tokens]\n",
    "    if len(vec) < max_len: vec += [0] * (max_len - len(vec))\n",
    "    else: vec = vec[:max_len]\n",
    "    return vec\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.X = torch.tensor([encode(t) for t in df['review_text']], dtype=torch.long)\n",
    "        self.y = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(LSTMDataset(train_df), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(LSTMDataset(test_df), batch_size=64)\n",
    "\n",
    "# GloVe Embeddings\n",
    "emb_dim = 100\n",
    "emb_matrix = np.random.normal(scale=0.6, size=(vocab_size, emb_dim))\n",
    "try:\n",
    "    print(\"Caricamento GloVe...\")\n",
    "    glove = api.load(\"glove-twitter-100\")\n",
    "    found = 0\n",
    "    for w, i in vocab.items():\n",
    "        if w in glove: \n",
    "            emb_matrix[i] = glove[w]\n",
    "            found += 1\n",
    "    print(f\"Trovate {found}/{vocab_size} parole in GloVe.\")\n",
    "except: print(\"GloVe non disponibile, uso random.\")\n",
    "\n",
    "# Modello LSTM\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
    "        self.emb.weight.requires_grad = False # Freeze GloVe\n",
    "        self.lstm = nn.LSTM(emb_dim, 64, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(128, len(labels_order))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(self.drop(torch.cat((h[-2], h[-1]), dim=1)))\n",
    "\n",
    "model_lstm = LSTMNet().to(device)\n",
    "opt = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for ep in range(5):\n",
    "    model_lstm.train()\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model_lstm(X), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(f\"LSTM Epoch {ep+1} complete\")\n",
    "\n",
    "# Valutazione\n",
    "model_lstm.eval()\n",
    "lstm_preds, lstm_true = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        preds = model_lstm(X).argmax(1).cpu().numpy()\n",
    "        lstm_preds.extend(preds)\n",
    "        lstm_true.extend(y.numpy())\n",
    "\n",
    "lstm_acc = accuracy_score(lstm_true, lstm_preds)\n",
    "lstm_f1 = f1_score(lstm_true, lstm_preds, average='weighted')\n",
    "print(f\"LSTM -> Accuracy: {lstm_acc:.4f} | F1: {lstm_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XLM-RoBERTa (LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_ds = HFDataset.from_dict({\"text\": train_df['review_text'].tolist(), \"label\": train_df['label'].tolist()}).map(tokenize, batched=True)\n",
    "val_ds = HFDataset.from_dict({\"text\": val_df['review_text'].tolist(), \"label\": val_df['label'].tolist()}).map(tokenize, batched=True)\n",
    "test_ds = HFDataset.from_dict({\"text\": test_df['review_text'].tolist(), \"label\": test_df['label'].tolist()}).map(tokenize, batched=True)\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(labels_order), id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=16, lora_alpha=32, lora_dropout=0.1, target_modules=[\"query\", \"value\"])\n",
    "model_bert = get_peft_model(base_model, peft_config)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds), \"f1\": f1_score(p.label_ids, preds, average='weighted')}\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../models/bert_lora_v2\", \n",
    "    num_train_epochs=2, \n",
    "    per_device_train_batch_size=16, \n",
    "    logging_steps=50, \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model_bert, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
    "trainer.train()\n",
    "\n",
    "bert_res = trainer.predict(test_ds)\n",
    "bert_acc = bert_res.metrics['test_accuracy']\n",
    "bert_f1 = bert_res.metrics['test_f1']\n",
    "print(f\"BERT -> Accuracy: {bert_acc:.4f} | F1: {bert_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confronto Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'LSTM (GloVe)', 'XLM-RoBERTa (LoRA)'],\n",
    "    'Accuracy': [nb_acc, lstm_acc, bert_acc],\n",
    "    'F1-Score': [nb_f1, lstm_f1, bert_f1]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "\n",
    "results.set_index('Model').plot(kind='bar', figsize=(10, 6), ylim=(0, 1), rot=0)\n",
    "plt.title('Confronto Prestazioni Modelli (5 Classi Bilanciate)')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
